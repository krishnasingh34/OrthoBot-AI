import React, { useState, useEffect, useRef } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { Mic, Phone, X } from 'lucide-react';
import '../CSS/VoiceCallingInterface.css';

const VoiceCallingInterface = ({ isOpen, onClose, selectedLanguage = 'en', onSaveVoiceHistory }) => {
  const [isListening, setIsListening] = useState(false);
  const [detectedLanguage, setDetectedLanguage] = useState('english');
  const [welcomeMessage, setWelcomeMessage] = useState('');
  const [isWelcomeSpoken, setIsWelcomeSpoken] = useState(false);
  const [connectionStatus, setConnectionStatus] = useState('connecting'); // connecting, connected, error
  const [isBotSpeaking, setIsBotSpeaking] = useState(false);
  const [conversationActive, setConversationActive] = useState(false);
  const [currentSessionId, setCurrentSessionId] = useState(null);
  const currentSessionIdRef = useRef(null);
  const recognitionRef = useRef(null);
  const speechSynthesisRef = useRef(null);
  const azureAudioRef = useRef(null);
  const azureAudioUrlRef = useRef(null);
  const conversationHistoryRef = useRef([]);
  const timeoutsRef = useRef([]);
  const isShuttingDownRef = useRef(false);

  // Helper to track and clear timeouts to avoid delayed restarts
  const addTimeout = (callback, delay) => {
    if (isShuttingDownRef.current) return null;
    const id = setTimeout(() => {
      if (!isShuttingDownRef.current) {
        callback();
      }
    }, delay);
    timeoutsRef.current.push(id);
    return id;
  };

  const clearAllTimeouts = () => {
    if (timeoutsRef.current.length) {
      timeoutsRef.current.forEach((id) => clearTimeout(id));
      timeoutsRef.current = [];
    }
  };

  // Get welcome message from backend
  const getWelcomeMessage = async (language) => {
    try {
      const backendUrl = import.meta.env.VITE_BACKEND_URL || 'http://localhost:3000';
      const response = await fetch(`${backendUrl}/api/greeting`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ language })
      });
      
      if (response.ok) {
        const data = await response.json();
        return data.greeting;
      }
    } catch (error) {
      console.error('Error fetching welcome message:', error);
    }
    
    // Fallback messages
    const fallbackMessages = {
      hindi: "à¤¹à¥ˆà¤²à¥‹! à¤®à¥ˆà¤‚ OrthoBot à¤¹à¥‚à¤‚à¥¤ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥€ orthopedic recovery à¤®à¥‡à¤‚ help à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¯à¤¹à¤¾à¤‚ à¤¹à¥‚à¤‚à¥¤ à¤†à¤ªà¤•à¥‹ à¤•à¥à¤¯à¤¾ problem à¤¹à¥ˆ?",
      english: "Hello! I'm OrthoBot AI, your orthopedic recovery assistant. I'm here to help you with your post-operative recovery journey. What can I help you with today?",
      hinglish: "à¤¹à¥ˆà¤²à¥‹! à¤®à¥ˆà¤‚ OrthoBot à¤¹à¥‚à¤‚à¥¤ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥€ orthopedic recovery à¤®à¥‡à¤‚ help à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¯à¤¹à¤¾à¤‚ à¤¹à¥‚à¤‚à¥¤ à¤†à¤ªà¤•à¥‹ à¤•à¥à¤¯à¤¾ problem à¤¹à¥ˆ?"
    };
    
    return fallbackMessages[language] || fallbackMessages.english;
  };

  // Start voice session
  const startVoiceSession = async () => {
    try {
      const backendUrl = import.meta.env.VITE_BACKEND_URL || 'http://localhost:3000';
      const response = await fetch(`${backendUrl}/api/voice/session/start`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          userId: 'voice-call-user',
          sessionType: 'voice_call'
        })
      });

      if (response.ok) {
        const data = await response.json();
        setCurrentSessionId(data.sessionId);
        currentSessionIdRef.current = data.sessionId;
        console.log('Voice session started:', data.sessionId);
        return data.sessionId;
      } else {
        throw new Error('Failed to start voice session');
      }
    } catch (error) {
      console.error('Error starting voice session:', error);
      return null;
    }
  };

  // End voice session
  const endVoiceSession = async (sessionId) => {
    if (!sessionId) return;
    
    try {
      const backendUrl = import.meta.env.VITE_BACKEND_URL || 'http://localhost:3000';
      const response = await fetch(`${backendUrl}/api/voice/session/end`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          sessionId
        })
      });

      if (response.ok) {
        const data = await response.json();
        console.log('Voice session ended:', data);
        setCurrentSessionId(null);
      }
    } catch (error) {
      console.error('Error ending voice session:', error);
    }
  };

  // Get bot response and speak it
  const getBotResponseAndSpeak = async (userMessage, language) => {
    try {
      setIsBotSpeaking(true);
      const backendUrl = import.meta.env.VITE_BACKEND_URL || 'http://localhost:3000';
      
      const response = await fetch(`${backendUrl}/askAI`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          query: userMessage,
          userId: 'voice-call-user',
          useConversationalAgent: true,
          source: 'voice',
          sessionId: currentSessionIdRef.current || currentSessionId
        })
      });

      if (response.ok) {
        const data = await response.json();
        // Sync sessionId from backend (in case server ensured/created a different one)
        if (data.sessionId && data.sessionId !== currentSessionIdRef.current) {
          setCurrentSessionId(data.sessionId);
          currentSessionIdRef.current = data.sessionId;
        }
        const botResponse = data.response || data.answer || 'Sorry, I could not process your request.';
        
        // Store in conversation history
        conversationHistoryRef.current.push({
          user: userMessage,
          bot: botResponse,
          timestamp: new Date()
        });
        
        // Speak the response and wait for it to complete
        await speakText(botResponse, language);
      } else {
        throw new Error('Failed to get bot response');
      }
    } catch (error) {
      console.error('Error getting bot response:', error);
      const errorMessage = language === 'hindi' ? 
        'à¤®à¤¾à¤« à¤•à¤°à¥‡à¤‚, à¤®à¥à¤à¥‡ à¤•à¥à¤› à¤¤à¤•à¤¨à¥€à¤•à¥€ à¤¸à¤®à¤¸à¥à¤¯à¤¾ à¤¹à¥‹ à¤°à¤¹à¥€ à¤¹à¥ˆà¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¥à¥‹à¤¡à¤¼à¥€ à¤¦à¥‡à¤° à¤¬à¤¾à¤¦ à¤•à¥‹à¤¶à¤¿à¤¶ à¤•à¤°à¥‡à¤‚à¥¤' :
        'I\'m sorry, I\'m experiencing some technical difficulties. Please try again in a moment.';
      await speakText(errorMessage, language);
    }
    // Note: setIsBotSpeaking(false) is handled in speakText function
  };

  // Speak text using Azure TTS
  const speakText = async (text, language) => {
    const useAzureTTS = import.meta.env.VITE_USE_AZURE_TTS === 'true';
    const azureKey = import.meta.env.VITE_AZURE_KEY;
    const azureRegion = import.meta.env.VITE_AZURE_REGION;
    const voice = 'hi-IN-AartiNeural'; // Use same voice for all languages
    
    setIsBotSpeaking(true);

    console.log('ðŸŽ¤ Azure TTS Debug:', { 
      useAzureTTS, 
      language, 
      voice,
      text: text.substring(0, 50) + '...' 
    });

    // Use Azure Speech Services TTS
    if (useAzureTTS && azureKey && azureRegion) {
      try {
        // Get Azure token
        const tokenResp = await fetch(`https://${azureRegion}.api.cognitive.microsoft.com/sts/v1.0/issueToken`, {
          method: "POST",
          headers: { "Ocp-Apim-Subscription-Key": azureKey }
        });
        
        if (!tokenResp.ok) {
          throw new Error(`Token request failed: ${tokenResp.status}`);
        }
        
        const token = await tokenResp.text();

        // Create SSML
        const ssml = `
          <speak version='1.0' xml:lang='hi-IN'>
            <voice name='${voice}'>${text}</voice>
          </speak>`;

        // Get TTS audio
        const ttsResp = await fetch(`https://${azureRegion}.tts.speech.microsoft.com/cognitiveservices/v1`, {
          method: "POST",
          headers: {
            "Authorization": `Bearer ${token}`,
            "Content-Type": "application/ssml+xml",
            "X-Microsoft-OutputFormat": "audio-16khz-128kbitrate-mono-mp3"
          },
          body: ssml
        });

        if (!ttsResp.ok) {
          throw new Error(`Azure TTS failed: ${ttsResp.status}`);
        }
        
        const audioBlob = await ttsResp.blob();
        const url = URL.createObjectURL(audioBlob);

        // Clean up previous audio
        if (azureAudioRef.current) {
          try { azureAudioRef.current.pause(); } catch {}
        }
        if (azureAudioUrlRef.current) {
          try { URL.revokeObjectURL(azureAudioUrlRef.current); } catch {}
        }

        // Store references
        azureAudioUrlRef.current = url;
        const audio = new Audio(url);
        azureAudioRef.current = audio;

        // Play audio and wait for completion
        return new Promise((resolve) => {
          audio.onended = () => {
            console.log('ðŸŽµ Azure TTS Ended');
            setIsBotSpeaking(false);
            URL.revokeObjectURL(url);
            azureAudioRef.current = null;
            azureAudioUrlRef.current = null;
            resolve();
          };
          
          audio.onerror = (error) => {
            console.error('ðŸš¨ Azure TTS Audio Error:', error);
            setIsBotSpeaking(false);
            URL.revokeObjectURL(url);
            azureAudioRef.current = null;
            azureAudioUrlRef.current = null;
            resolve();
          };
          
          console.log('ðŸŽµ Azure TTS Started');
          audio.play().catch((error) => {
            console.error('ðŸš¨ Azure TTS Play Error:', error);
            setIsBotSpeaking(false);
            URL.revokeObjectURL(url);
            azureAudioRef.current = null;
            azureAudioUrlRef.current = null;
            resolve();
          });
        });
      } catch (err) {
        console.error("Azure TTS failed:", err);
        setIsBotSpeaking(false);
        // Fall back to browser TTS
      }
    }

    // Fallback to browser speechSynthesis
    console.log('ðŸŽ¤ Falling back to browser TTS');
    if (!window.speechSynthesis) {
      setIsBotSpeaking(false);
      return;
    }
    
    return new Promise((resolve) => {
      window.speechSynthesis.cancel();
      const utterance = new SpeechSynthesisUtterance(text);
      
      if (language === 'hindi' || language === 'hinglish') {
        utterance.lang = 'hi-IN';
      } else {
        utterance.lang = 'en-IN';
      }
      
      utterance.onstart = () => {
        setIsBotSpeaking(true);
        console.log('ðŸŽµ Browser TTS Started');
      };
      
      utterance.onend = () => { 
        setIsBotSpeaking(false); 
        console.log('ðŸŽµ Browser TTS Ended');
        resolve(); 
      };
      
      utterance.onerror = (error) => { 
        setIsBotSpeaking(false); 
        console.error('ðŸš¨ Browser TTS Error:', error);
        resolve(); 
      };
      
      speechSynthesisRef.current = utterance;
      window.speechSynthesis.speak(utterance);
    });
  };

  // Detect language from text
  const detectLanguage = (text) => {
    const hindiPattern = /[\u0900-\u097F]/; // Devanagari script
    const englishPattern = /^[a-zA-Z\s.,!?'"()-]+$/;
    
    const hasHindi = hindiPattern.test(text);
    const hasEnglish = englishPattern.test(text);
    
    if (hasHindi && hasEnglish) return 'hinglish';
    if (hasHindi) return 'hindi';
    return 'english';
  };

  // Speak welcome message
  const speakWelcomeMessage = async (language) => {
    try {
      // Start voice session first
      const sessionId = await startVoiceSession();
      if (!sessionId) {
        throw new Error('Failed to start voice session');
      }
      
      const message = await getWelcomeMessage(language);
      setConnectionStatus('connected');
      
      await speakText(message, language);
      
      setIsWelcomeSpoken(true);
      setConversationActive(true);
      
      // Start listening after welcome message
      addTimeout(() => {
        startListening();
      }, 500);
    } catch (error) {
      console.error('Error speaking welcome message:', error);
      setConnectionStatus('error');
    }
  };

  // Start voice recognition
  const startListening = () => {
    try {
      if (isShuttingDownRef.current) return;
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        alert('Speech recognition is not supported in this browser. Please use Chrome or Edge.');
        return;
      }

      const recognition = new SpeechRecognition();
      recognitionRef.current = recognition;
      
      // Set language based on selected language from Chat component
      if (selectedLanguage === 'hi') {
        recognition.lang = 'hi-IN';
      } else {
        recognition.lang = 'en-US';
      }
      
      recognition.interimResults = true;
      recognition.maxAlternatives = 1;
      recognition.continuous = false;

      setIsListening(true);

      recognition.onresult = (event) => {
        let finalTranscript = '';
        let interimTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }

        // Store final transcript for later use
        recognition.finalTranscript = finalTranscript;

        // Update detected language based on what user says
        const userText = finalTranscript || interimTranscript;
        if (userText.trim()) {
          const newLanguage = detectLanguage(userText);
          if (newLanguage !== detectedLanguage) {
            setDetectedLanguage(newLanguage);
          }
        }
      };

      recognition.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        setIsListening(false);
        
        // Restart listening for most errors, except aborted
        if (event.error !== 'aborted' && isOpen && conversationActive) {
          addTimeout(() => {
            if (isOpen && conversationActive) {
              console.log('Restarting listening after error:', event.error);
              startListening();
            }
          }, 1000);
        }
      };

      recognition.onend = () => {
        setIsListening(false);
        console.log('Recognition ended, final transcript:', recognition.finalTranscript);
        
        // If we have final transcript, get bot response and continue conversation
        if (!isShuttingDownRef.current && recognition && recognition.finalTranscript && recognition.finalTranscript.trim()) {
          const userMessage = recognition.finalTranscript.trim();
          const currentLanguage = selectedLanguage === 'hi' ? 'hindi' : 'english';
          
          console.log('Processing user message:', userMessage);
          
          // Get bot response and speak it
          getBotResponseAndSpeak(userMessage, currentLanguage).then(() => {
            console.log('Bot finished speaking, restarting listening...');
            // After bot finishes speaking, start listening again
            if (!isShuttingDownRef.current && isOpen && conversationActive) {
              addTimeout(() => {
                console.log('Starting listening again...');
                startListening();
              }, 1500); // Increased delay to ensure bot has finished
            }
          }).catch((error) => {
            console.error('Error in bot response chain:', error);
            // Even if there's an error, try to restart listening
            if (!isShuttingDownRef.current && isOpen && conversationActive) {
              addTimeout(() => {
                startListening();
              }, 2000);
            }
          });
        } else {
          console.log('No final transcript, restarting listening...');
          // Restart listening if no final result
          addTimeout(() => {
            if (!isShuttingDownRef.current && isOpen && conversationActive) {
              startListening();
            }
          }, 1000);
        }
      };

      recognition.start();
    } catch (error) {
      console.error('Error starting speech recognition:', error);
      setIsListening(false);
    }
  };

  // Initialize calling interface
  useEffect(() => {
    if (isOpen) {
      console.log('Voice interface opening - initializing fresh state');
      isShuttingDownRef.current = false;
      
      // Ensure clean state
      setConnectionStatus('connecting');
      setIsWelcomeSpoken(false);
      setIsListening(false);
      setIsBotSpeaking(false);
      setConversationActive(false);
      
      // Clear any existing recognition
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
          recognitionRef.current.abort();
        } catch (error) {
          console.log('Error stopping existing recognition:', error);
        }
        recognitionRef.current = null;
      }
      
      // Clear any existing speech synthesis
      if (speechSynthesisRef.current) {
        window.speechSynthesis.cancel();
        speechSynthesisRef.current = null;
      }
      // Stop any ongoing Azure audio playback
      if (azureAudioRef.current) {
        try { azureAudioRef.current.pause(); } catch {}
        azureAudioRef.current = null;
      }
      if (azureAudioUrlRef.current) {
        try { URL.revokeObjectURL(azureAudioUrlRef.current); } catch {}
        azureAudioUrlRef.current = null;
      }
      
      // Simulate connection delay
      addTimeout(async () => {
        // Use the selected language from Chat component
        const initialLanguage = selectedLanguage === 'hi' ? 'hindi' : 'english';
        setDetectedLanguage(initialLanguage);
        
        // Speak welcome message in the selected language
        await speakWelcomeMessage(initialLanguage);
      }, 1000);
    }
  }, [isOpen, selectedLanguage]);

  // Cleanup on close
  useEffect(() => {
    if (!isOpen) {
      console.log('Voice interface closed - cleaning up all audio');
      isShuttingDownRef.current = true;
      
      // End voice session if it exists
      if (currentSessionId) {
        endVoiceSession(currentSessionId);
      }
      
      // Clear any scheduled timeouts
      clearAllTimeouts();

      // Completely stop and destroy speech recognition
      if (recognitionRef.current) {
        try {
          recognitionRef.current.onend = null;
          recognitionRef.current.onerror = null;
          recognitionRef.current.stop();
          recognitionRef.current.abort();
        } catch (error) {
          console.log('Error stopping recognition in cleanup:', error);
        }
        recognitionRef.current = null;
      }
      
      // Stop speech synthesis
      window.speechSynthesis.cancel();
      speechSynthesisRef.current = null;
      
      // Reset all states
      setIsListening(false);
      setIsWelcomeSpoken(false);
      setConnectionStatus('connecting');
      setConversationActive(false);
      setIsBotSpeaking(false);
      setCurrentSessionId(null);
      
      // Clear conversation history
      conversationHistoryRef.current = [];
    }
  }, [isOpen]);

  // Fallback mechanism to ensure conversation continues
  useEffect(() => {
    if (isOpen && conversationActive && !isListening && !isBotSpeaking && isWelcomeSpoken) {
      console.log('Fallback: Starting listening due to inactive state');
      const timer = addTimeout(() => {
        if (isOpen && conversationActive && !isListening && !isBotSpeaking) {
          startListening();
        }
      }, 3000); // 3 second fallback
      
      return () => clearTimeout(timer);
    }
  }, [isOpen, conversationActive, isListening, isBotSpeaking, isWelcomeSpoken]);

  // Cleanup on component unmount
  useEffect(() => {
    return () => {
      console.log('Voice interface component unmounting - final cleanup');
      // Final cleanup when component is destroyed
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
          recognitionRef.current.abort();
        } catch (error) {
          console.log('Error in final cleanup:', error);
        }
        recognitionRef.current = null;
      }
      
      if (speechSynthesisRef.current) {
        window.speechSynthesis.cancel();
        speechSynthesisRef.current = null;
      }
    };
  }, []);

  // Save voice conversation to chat history
  const saveVoiceConversationToHistory = async (sessionId) => {
    if (!sessionId || !onSaveVoiceHistory) return;
    
    try {
      const backendUrl = import.meta.env.VITE_BACKEND_URL || 'http://localhost:3000';
      const response = await fetch(`${backendUrl}/api/voice/session/history`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          sessionId
        })
      });

      if (response.ok) {
        const data = await response.json();
        console.log('Voice session history retrieved:', data);
        
        // Convert voice conversation to chat format
        if (data.conversationHistory && data.conversationHistory.length > 0) {
          const chatMessages = data.conversationHistory.map((msg, index) => ({
            id: Date.now() + index,
            type: msg.role === 'user' ? 'user' : 'bot',
            text: msg.content,
            timestamp: new Date(msg.timestamp).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })
          }));
          
          // Generate chat title based on first few user messages for better intent detection
          const userMessages = data.conversationHistory
            .filter(msg => msg.role === 'user')
            .slice(0, 3)
            .map(msg => msg.content)
            .join(' ');
          
          const chatTitle = userMessages ? 
            extractVoiceCallIntent(userMessages) : 
            'General Conversations';
          
          // Save to chat history via callback
          onSaveVoiceHistory(chatMessages, chatTitle);
          console.log('Voice conversation saved to chat history:', chatTitle);
        }
      }
    } catch (error) {
      console.error('Error saving voice conversation to history:', error);
    }
  };

  // Extract intent from voice call for chat title
  const extractVoiceCallIntent = (text) => {
    const cleanText = text.toLowerCase().trim();
    console.log('ðŸŽ¯ Analyzing text for intent:', cleanText);
    console.log('ðŸŽ¯ Text length:', cleanText.length);
    
    // Intent patterns for meaningful chat titles (without "Voice Call:" prefix)
    const intentPatterns = {
      'Post-operative Care': ['post-operative', 'post operative', 'after surgery', 'post surgery', 'operation ke baad', 'surgery ke baad', 'à¤¸à¤°à¥à¤œà¤°à¥€ à¤•à¥‡ à¤¬à¤¾à¤¦', 'à¤‘à¤ªà¤°à¥‡à¤¶à¤¨ à¤•à¥‡ à¤¬à¤¾à¤¦', 'surgery baad', 'operation baad'],
      'Knee Recovery': ['knee', 'knee pain', 'knee surgery', 'knee injury', 'à¤˜à¥à¤Ÿà¤¨à¤¾', 'à¤˜à¥à¤Ÿà¤¨à¥‡ à¤®à¥‡à¤‚ à¤¦à¤°à¥à¤¦', 'ghutna', 'knee ka dard'],
      'Back Pain Relief': ['back pain', 'back injury', 'back surgery', 'spine', 'à¤•à¤®à¤° à¤¦à¤°à¥à¤¦', 'à¤ªà¥€à¤  à¤¦à¤°à¥à¤¦', 'kamar dard', 'back mein dard'],
      'Shoulder Rehabilitation': ['shoulder', 'shoulder pain', 'shoulder surgery', 'shoulder injury', 'à¤•à¤‚à¤§à¤¾', 'à¤•à¤‚à¤§à¥‡ à¤®à¥‡à¤‚ à¤¦à¤°à¥à¤¦', 'kandha'],
      'Hip Recovery': ['hip', 'hip replacement', 'hip surgery', 'hip pain', 'à¤•à¥‚à¤²à¥à¤¹à¤¾', 'à¤•à¥‚à¤²à¥à¤¹à¥‡ à¤®à¥‡à¤‚ à¤¦à¤°à¥à¤¦', 'kulha'],
      'Exercise & Therapy': ['exercise', 'workout', 'physical therapy', 'stretching', 'à¤µà¥à¤¯à¤¾à¤¯à¤¾à¤®', 'à¤à¤•à¥à¤¸à¤°à¤¸à¤¾à¤‡à¤œ', 'physio'],
      'Recovery Timeline': ['recovery time', 'how long', 'timeline', 'healing time', 'à¤•à¤¿à¤¤à¤¨à¤¾ à¤¸à¤®à¤¯', 'à¤•à¤¬ à¤¤à¤•', 'kitna samay'],
      'Pain Management': ['pain relief', 'manage pain', 'reduce pain', 'pain medication', 'à¤¦à¤°à¥à¤¦ à¤•à¤® à¤•à¤°à¤¨à¤¾', 'dard kam karna'],
      'Mobility Issues': ['mobility', 'movement', 'range of motion', 'flexibility', 'à¤šà¤²à¤¨à¥‡ à¤®à¥‡à¤‚', 'à¤¹à¤¿à¤²à¤¨à¥‡ à¤®à¥‡à¤‚', 'chalne mein'],
      'Wound Care': ['wound', 'incision', 'stitches', 'healing', 'à¤˜à¤¾à¤µ', 'à¤Ÿà¤¾à¤‚à¤•à¥‡', 'ghav', 'tanke'],
      'Return to Activities': ['return to work', 'return to sport', 'normal activities', 'à¤•à¤¾à¤® à¤ªà¤° à¤µà¤¾à¤ªà¤¸', 'kaam par wapas'],
      'Diabetes Management': ['diabetes', 'sugar', 'blood sugar', 'glucose', 'insulin', 'à¤¶à¥à¤—à¤°', 'à¤®à¤§à¥à¤®à¥‡à¤¹', 'à¤¡à¤¾à¤¯à¤¬à¤¿à¤Ÿà¥€à¤œ'],
      'Blood Pressure Issues': ['blood pressure', 'bp high', 'bp low', 'hypertension', 'à¤¬à¥à¤²à¤¡ à¤ªà¥à¤°à¥‡à¤¶à¤°', 'à¤¹à¤¾à¤ˆ à¤¬à¥€à¤ªà¥€'],
      'Heart Problems': ['heart', 'chest pain', 'heart attack', 'cardiac', 'à¤¦à¤¿à¤²', 'à¤¸à¥€à¤¨à¥‡ à¤®à¥‡à¤‚ à¤¦à¤°à¥à¤¦', 'heart attack'],
      'Breathing Issues': ['breathing', 'asthma', 'cough', 'lungs', 'à¤¸à¤¾à¤‚à¤¸', 'à¤–à¤¾à¤‚à¤¸à¥€', 'à¤¦à¤® à¤˜à¥à¤Ÿà¤¨à¤¾', 'saas'],
      'Mental Health': ['depression', 'anxiety', 'stress', 'à¤¤à¤¨à¤¾à¤µ', 'à¤šà¤¿à¤‚à¤¤à¤¾', 'à¤¡à¤¿à¤ªà¥à¤°à¥‡à¤¶à¤¨', 'tanav'],
      'General Health': ['health', 'wellness', 'checkup', 'à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯', 'à¤¸à¥‡à¤¹à¤¤', 'swasthya']
    };
    
    // Find matching intent for medical topics
    for (const [intent, keywords] of Object.entries(intentPatterns)) {
      const matchedKeyword = keywords.find(keyword => cleanText.includes(keyword));
      if (matchedKeyword) {
        console.log('âœ… Found medical intent match:', intent, 'for keyword:', matchedKeyword);
        return intent;
      }
    }
    console.log('âŒ No specific medical intent matches found');
    
    // Fallback: extract key medical terms and create meaningful titles
    const medicalTerms = {
      'surgery': 'Surgery Consultation',
      'à¤¸à¤°à¥à¤œà¤°à¥€': 'Surgery Consultation',
      'à¤‘à¤ªà¤°à¥‡à¤¶à¤¨': 'Surgery Consultation',
      'recovery': 'Recovery Questions', 
      'pain': 'Pain Relief',
      'therapy': 'Therapy Guidance',
      'exercise': 'Exercise Questions',
      'treatment': 'Treatment Discussion',
      'injury': 'Injury Consultation',
      'healing': 'Healing Process',
      'medicine': 'Medication Questions',
      'doctor': 'Medical Consultation',
      'hospital': 'Hospital Related',
      'à¤¦à¤°à¥à¤¦': 'Pain Relief',
      'à¤‡à¤²à¤¾à¤œ': 'Treatment Discussion',
      'à¤¦à¤µà¤¾': 'Medication Questions',
      'à¤¡à¥‰à¤•à¥à¤Ÿà¤°': 'Medical Consultation'
    };
    
    for (const [term, title] of Object.entries(medicalTerms)) {
      if (cleanText.includes(term)) {
        console.log('âœ… Found medical term match:', title, 'for term:', term);
        return title;
      }
    }
    console.log('âŒ No medical term matches found');
    // Check for non-medical/off-topic conversations
    const offTopicPatterns = {
      'Weather Discussion': [
        'weather', 'rain', 'hot', 'cold', 'temperature',
        'à¤®à¥Œà¤¸à¤®', 'à¤¬à¤¾à¤°à¤¿à¤¶', 'à¤—à¤°à¥à¤®à¥€', 'à¤ à¤‚à¤¡', 'mausam'
      ],
    
      'Technology Talk': [
        'computer', 'phone', 'internet', 'software', 'app', 'website',
        'à¤•à¤‚à¤ªà¥à¤¯à¥‚à¤Ÿà¤°', 'à¤«à¥‹à¤¨', 'à¤‡à¤‚à¤Ÿà¤°à¤¨à¥‡à¤Ÿ'
      ],
    
      'Food & Cooking': [
        'food', 'cooking', 'recipe', 'eat', 'meal',
        'à¤–à¤¾à¤¨à¤¾', 'à¤–à¤¾à¤¨à¤¾ à¤¬à¤¨à¤¾à¤¨à¤¾', 'à¤°à¥‡à¤¸à¤¿à¤ªà¥€', 'khana'
      ],
    
      'Sports Discussion': [
        'cricket', 'football', 'sports', 'match', 'game',
        'à¤–à¥‡à¤²', 'à¤®à¥ˆà¤š', 'à¤•à¥à¤°à¤¿à¤•à¥‡à¤Ÿ', 'khel'
      ],
    
      'Celebrity Discussion': [
        'celebrity', 'actor', 'actress', 'singer', 'star', 'bollywood', 'hollywood',
        'film', 'movie',
        'à¤¸à¥‡à¤²à¤¿à¤¬à¥à¤°à¤¿à¤Ÿà¥€', 'à¤…à¤­à¤¿à¤¨à¥‡à¤¤à¤¾', 'à¤…à¤­à¤¿à¤¨à¥‡à¤¤à¥à¤°à¥€', 'à¤—à¤¾à¤¯à¤•', 'à¤¸à¥à¤Ÿà¤¾à¤°', 'à¤¬à¥‰à¤²à¥€à¤µà¥à¤¡', 'à¤¹à¥‰à¤²à¥€à¤µà¥à¤¡', 'à¤«à¤¿à¤²à¥à¤®',
        'famous', 'popular', 'superstar', 'hero', 'heroine', 'artist', 'performer',
        'à¤ªà¥à¤°à¤¸à¤¿à¤¦à¥à¤§', 'à¤®à¤¶à¤¹à¥‚à¤°', 'à¤¸à¥à¤ªà¤°à¤¸à¥à¤Ÿà¤¾à¤°', 'à¤¹à¥€à¤°à¥‹', 'à¤¹à¥€à¤°à¥‹à¤‡à¤¨', 'à¤•à¤²à¤¾à¤•à¤¾à¤°',
        'khan', 'kumar', 'singh', 'sharma', 'kapoor', 'bhatt', 'chopra', 'kaif',
        'à¤–à¤¾à¤¨', 'à¤•à¥à¤®à¤¾à¤°', 'à¤¸à¤¿à¤‚à¤¹', 'à¤¶à¤°à¥à¤®à¤¾', 'à¤•à¤ªà¥‚à¤°', 'à¤­à¤Ÿà¥à¤Ÿ', 'à¤šà¥‹à¤ªà¤¡à¤¼à¤¾', 'à¤•à¥ˆà¤«',
        'acting', 'singing', 'dancing', 'performance', 'concert', 'album', 'song',
        'à¤…à¤­à¤¿à¤¨à¤¯', 'à¤—à¤¾à¤¯à¤¨', 'à¤¨à¥ƒà¤¤à¥à¤¯', 'à¤ªà¥à¤°à¤¦à¤°à¥à¤¶à¤¨', 'à¤•à¥‰à¤¨à¥à¤¸à¤°à¥à¤Ÿ', 'à¤à¤²à¥à¤¬à¤®', 'à¤—à¤¾à¤¨à¤¾'
      ],
    
      'Entertainment': [
        'music', 'song', 'tv', 'show', 'series',
        'à¤—à¤¾à¤¨à¤¾', 'à¤¸à¤‚à¤—à¥€à¤¤', 'à¤Ÿà¥€à¤µà¥€', 'à¤¶à¥‹'
      ],
    
      'Travel & Places': [
        'travel', 'trip', 'place', 'city', 'country', 'flight', 'train', 'ticket', 'hotel',
        'à¤¯à¤¾à¤¤à¥à¤°à¤¾', 'à¤¸à¤«à¤°', 'à¤œà¤—à¤¹', 'à¤ªà¤¾à¤¸à¤ªà¥‹à¤°à¥à¤Ÿ', 'à¤¹à¥‹à¤Ÿà¤²', 'à¤µà¤¿à¤¸à¤¾', 'yatra', 'safar'
      ],
    
      'Education & Learning': [
        'study', 'school', 'college', 'education', 'learn',
        'à¤ªà¤¢à¤¼à¤¾à¤ˆ', 'à¤¸à¥à¤•à¥‚à¤²', 'à¤•à¥‰à¤²à¥‡à¤œ', 'padhai'
      ],
    
      'Work & Career': [
        'job', 'work', 'office', 'career', 'business',
        'à¤•à¤¾à¤®', 'à¤¨à¥Œà¤•à¤°à¥€', 'à¤‘à¤«à¤¿à¤¸', 'kaam', 'naukri'
      ],
    
      'Family & Relationships': [
        'family', 'friend', 'relationship', 'marriage',
        'à¤ªà¤°à¤¿à¤µà¤¾à¤°', 'à¤¦à¥‹à¤¸à¥à¤¤', 'à¤¶à¤¾à¤¦à¥€', 'parivar'
      ],
    
      'Shopping & Money': [
        'shopping', 'buy', 'sell', 'money', 'price',
        'amazon', 'flipkart', 'myntra', 'nike', 'adidas', 'brand',
        'à¤–à¤°à¥€à¤¦à¤¾à¤°à¥€', 'à¤ªà¥ˆà¤¸à¤¾', 'à¤•à¥€à¤®à¤¤', 'kharidari', 'à¤¬à¥à¤°à¤¾à¤‚à¤¡', 'à¤‘à¤¨à¤²à¤¾à¤‡à¤¨ à¤¶à¥‰à¤ªà¤¿à¤‚à¤—'
      ],
    
      'News & Current Events': [
        'news', 'politics', 'government', 'election',
        'à¤¸à¤®à¤¾à¤šà¤¾à¤°', 'à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿', 'à¤¸à¤°à¤•à¤¾à¤°', 'samachar'
      ],
    
      'Hobbies & Interests': [
        'hobby', 'interest', 'reading', 'painting',
        'à¤¶à¥Œà¤•', 'à¤°à¥à¤šà¤¿', 'à¤ªà¤¢à¤¼à¤¨à¤¾', 'shauk'
      ],
    
      'General Chat': [
        'hello', 'hi', 'how are you', 'good morning', 'good evening', 'how are you doing',
        'what\'s up', 'hey', 'greetings', 'nice to meet you', 'pleased to meet you',
        'à¤¨à¤®à¤¸à¥à¤¤à¥‡', 'à¤¹à¥ˆà¤²à¥‹', 'à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚', 'à¤•à¥à¤¯à¤¾ à¤¹à¤¾à¤² à¤¹à¥ˆ', 'à¤•à¥ˆà¤¸à¥‡ à¤¹à¥‹', 'à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚'
      ],
    
      // ðŸ†• Extra categories
    
      'Religion & Spirituality': [
        'god', 'bhagwan', 'allah', 'temple', 'church', 'mandir', 'masjid',
        'à¤§à¤°à¥à¤®', 'à¤­à¤—à¤µà¤¾à¤¨', 'à¤®à¤‚à¤¦à¤¿à¤°', 'à¤®à¤¸à¥à¤œà¤¿à¤¦', 'à¤§à¤¾à¤°à¥à¤®à¤¿à¤•', 'spiritual', 'prayer'
      ],
    
      'Politics & Leaders': [
        'prime minister', 'president', 'minister', 'bjp', 'congress', 'vote',
        'à¤®à¥‹à¤¦à¥€', 'à¤¯à¥‹à¤—à¥€', 'à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤•', 'election', 'government policy'
      ],
    
      'Finance & Crypto': [
        'bitcoin', 'crypto', 'stock', 'trading', 'investment', 'shares',
        'à¤®à¥à¤¦à¥à¤°à¤¾', 'à¤¶à¥‡à¤¯à¤°', 'à¤¨à¤¿à¤µà¥‡à¤¶', 'à¤ªà¥ˆà¤¸à¤¾ à¤•à¤®à¤¾à¤¨à¤¾', 'finance', 'bank loan'
      ],
    
      'Movies & OTT': [
        'netflix', 'amazon prime', 'zee5', 'hotstar', 'movie review', 'trailer',
        'à¤«à¤¿à¤²à¥à¤® à¤¦à¥‡à¤–à¤¨à¤¾', 'à¤¸à¥€à¤°à¥€à¤œ', 'à¤µà¥‡à¤¬ à¤¸à¥€à¤°à¥€à¤œ', 'à¤“à¤Ÿà¥€à¤Ÿà¥€'
      ],
    
      'Gaming': [
        'pubg', 'free fire', 'minecraft', 'valorant', 'bgmi', 'gameplay',
        'à¤–à¥‡à¤²à¤¨à¤¾', 'à¤—à¥‡à¤®à¤¿à¤‚à¤—', 'video game'
      ],
    
      'Fashion & Lifestyle': [
        'clothes', 'fashion', 'style', 'makeup', 'shoes', 'trend',
        'à¤•à¤ªà¤¡à¤¼à¥‡', 'à¤«à¥ˆà¤¶à¤¨', 'à¤¸à¥à¤Ÿà¤¾à¤‡à¤²', 'à¤¸à¥Œà¤‚à¤¦à¤°à¥à¤¯ à¤ªà¥à¤°à¤¸à¤¾à¤§à¤¨', 'à¤œà¥‚à¤¤à¥‡'
      ],
    
      'Astrology & Superstition': [
        'zodiac', 'rashifal', 'kundli', 'horoscope', 'astrology', 'vastu',
        'à¤œà¥à¤¯à¥‹à¤¤à¤¿à¤·', 'à¤°à¤¾à¤¶à¤¿', 'à¤•à¥à¤‚à¤¡à¤²à¥€', 'à¤­à¤¾à¤—à¥à¤¯'
      ],
    
      'Random Fun / Jokes': [
        'joke', 'funny', 'meme', 'à¤¹à¤‚à¤¸à¥€', 'à¤šà¥à¤Ÿà¤•à¥à¤²à¤¾', 'à¤®à¤œà¥‡à¤¦à¤¾à¤°'
      ],
    
      // ðŸ†• From my extended list
      'Love & Dating': [
        'love', 'girlfriend', 'boyfriend', 'date', 'romance', 'crush', 'kiss',
        'à¤ªà¥à¤¯à¤¾à¤°', 'à¤ªà¥à¤°à¥‡à¤®', 'à¤—à¤°à¥à¤²à¤«à¥à¤°à¥‡à¤‚à¤¡', 'à¤¬à¥‰à¤¯à¤«à¥à¤°à¥‡à¤‚à¤¡', 'à¤°à¥‹à¤®à¤¾à¤‚à¤¸', 'à¤¡à¥‡à¤Ÿ'
      ],
    
      'Festivals & Culture': [
        'diwali', 'holi', 'eid', 'christmas', 'festival', 'celebration',
        'à¤¤à¥à¤¯à¥‹à¤¹à¤¾à¤°', 'à¤¹à¥‹à¤²à¥€', 'à¤¦à¥€à¤µà¤¾à¤²à¥€', 'à¤ˆà¤¦', 'à¤•à¥à¤°à¤¿à¤¸à¤®à¤¸', 'à¤‰à¤¤à¥à¤¸à¤µ'
      ],
    
      'Animals & Pets': [
        'dog', 'cat', 'pet', 'animal', 'puppy', 'kitten', 'bird',
        'à¤•à¥à¤¤à¥à¤¤à¤¾', 'à¤¬à¤¿à¤²à¥à¤²à¥€', 'à¤ªà¤¶à¥', 'à¤ªà¤¾à¤²à¤¤à¥‚'
      ],
    
      'Vehicles & Automobiles': [
        'car', 'bike', 'motorcycle', 'bus', 'truck', 'engine', 'mileage',
        'à¤•à¤¾à¤°', 'à¤¬à¤¾à¤‡à¤•', 'à¤µà¤¾à¤¹à¤¨', 'à¤—à¤¾à¤¡à¤¼à¥€', 'à¤®à¥‹à¤Ÿà¤°'
      ],
    
      'Science & Space': [
        'space', 'nasa', 'moon', 'mars', 'rocket', 'planet', 'alien',
        'à¤…à¤‚à¤¤à¤°à¤¿à¤•à¥à¤·', 'à¤šà¤¾à¤à¤¦', 'à¤®à¤‚à¤—à¤²', 'à¤—à¥à¤°à¤¹', 'à¤°à¥‰à¤•à¥‡à¤Ÿ'
      ],
    
      'History & Kings': [
        'history', 'freedom', 'independence', 'ancient', 'king', 'queen',
        'à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸', 'à¤¸à¥à¤µà¤¤à¤‚à¤¤à¥à¤°à¤¤à¤¾', 'à¤°à¤¾à¤œà¤¾', 'à¤°à¤¾à¤¨à¥€', 'à¤ªà¥à¤°à¤¾à¤¨à¤¾ à¤œà¤®à¤¾à¤¨à¤¾'
      ],
    
      'Home & Daily Life': [
        'house', 'cleaning', 'laundry', 'kitchen', 'furniture', 'rent',
        'à¤˜à¤°', 'à¤¸à¤«à¤¾à¤ˆ', 'à¤•à¤ªà¤¡à¤¼à¥‡ à¤§à¥‹à¤¨à¤¾', 'à¤«à¤°à¥à¤¨à¥€à¤šà¤°', 'à¤•à¤¿à¤°à¤¾à¤¯à¤¾'
      ],
    
      'Math & Puzzles': [
        'math', 'algebra', 'geometry', 'puzzle', 'riddle',
        'à¤—à¤£à¤¿à¤¤', 'à¤ªà¤¹à¥‡à¤²à¥€', 'à¤¸à¤®à¤¸à¥à¤¯à¤¾', 'à¤—à¤£à¤¨à¤¾'
      ],
    
      'Programming & Coding': [
        'java', 'python', 'react', 'code', 'bug', 'software error',
        'à¤•à¥‹à¤¡à¤¿à¤‚à¤—', 'à¤ªà¥à¤°à¥‹à¤—à¥à¤°à¤¾à¤®à¤¿à¤‚à¤—', 'à¤¸à¥‰à¤«à¥à¤Ÿà¤µà¥‡à¤¯à¤°'
      ]
    };
    

    // Check for off-topic conversations - return same title for all non-medical topics
    for (const [intent, keywords] of Object.entries(offTopicPatterns)) {
      const matchedKeyword = keywords.find(keyword => cleanText.includes(keyword));
      if (matchedKeyword) {
        console.log('âœ… Found off-topic match:', intent, 'for keyword:', matchedKeyword);
        return 'General Conversations'; // Same title for all non-medical conversations
      }
    }
    console.log('âŒ No off-topic matches found');

    // Check for general conversation topics - all return same title
    if (cleanText.includes('help') || cleanText.includes('à¤®à¤¦à¤¦') || cleanText.includes('madad')) {
      return 'General Conversations';
    }
    
    if (cleanText.includes('question') || cleanText.includes('à¤¸à¤µà¤¾à¤²') || cleanText.includes('sawal')) {
      return 'General Conversations';
    }

    // Check if it contains any personal pronouns or casual conversation
    const casualConversation = ['i am', 'i was', 'i will', 'my name', 'tell me about', 'what is', 'how to', 
                               'à¤®à¥ˆà¤‚ à¤¹à¥‚à¤‚', 'à¤®à¥‡à¤°à¤¾ à¤¨à¤¾à¤®', 'à¤¬à¤¤à¤¾à¤‡à¤', 'à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ', 'à¤•à¥ˆà¤¸à¥‡ à¤•à¤°à¥‡à¤‚', 'main hun'];
    
    if (casualConversation.some(phrase => cleanText.includes(phrase))) {
      return 'General Conversations';
    }
    
    // Final fallback - for unclear conversations that don't match any category
    console.log('ðŸ”„ Using final fallback: General Conversations');
    return 'General Conversations';
  };

  // Handle end call
  const handleEndCall = async () => {
    console.log('Ending call - stopping all audio and recognition');
    isShuttingDownRef.current = true;

    // Stop any scheduled restarts/timeouts immediately
    clearAllTimeouts();

    // Save voice conversation to chat history before ending session
    if (currentSessionId) {
      await saveVoiceConversationToHistory(currentSessionId);
    }

    // Stop all audio and conversation immediately
    setConversationActive(false);
    setIsListening(false);
    setIsBotSpeaking(false);

    // Completely stop and destroy speech recognition immediately
    if (recognitionRef.current) {
      try {
        // Remove handlers to avoid any retries or restarts
        recognitionRef.current.onend = null;
        recognitionRef.current.onerror = null;
        // Abort first to force immediate termination in some browsers
        recognitionRef.current.abort();
        recognitionRef.current.stop();
      } catch (error) {
        console.log('Error stopping recognition:', error);
      }
      recognitionRef.current = null;
    }

    // Stop speech synthesis immediately
    window.speechSynthesis.cancel();
    speechSynthesisRef.current = null;
    // Stop Azure audio immediately
    if (azureAudioRef.current) {
      try { azureAudioRef.current.pause(); } catch {}
      azureAudioRef.current = null;
    }
    if (azureAudioUrlRef.current) {
      try { URL.revokeObjectURL(azureAudioUrlRef.current); } catch {}
      azureAudioUrlRef.current = null;
    }

    // Clear conversation history
    conversationHistoryRef.current = [];

    // Close modal immediately without waiting for backend
    onClose();

    // End voice session in background (non-blocking)
    if (currentSessionId) {
      endVoiceSession(currentSessionId);
    }
  };

  if (!isOpen) return null;

  return (
    <AnimatePresence>
      <motion.div
        className="voice-calling-overlay"
        initial={{ opacity: 0 }}
        animate={{ opacity: 1 }}
        exit={{ opacity: 0 }}
        transition={{ duration: 0.3 }}
      >
        <motion.div
          className="voice-calling-interface"
          initial={{ scale: 0.8, opacity: 0 }}
          animate={{ scale: 1, opacity: 1 }}
          exit={{ scale: 0.8, opacity: 0 }}
          transition={{ duration: 0.3 }}
        >
          {/* Close button */}
          <button className="close-btn" onClick={handleEndCall}>
            <X size={20} />
          </button>

          {/* Connection status */}
          <div className="connection-status">
            {connectionStatus === 'connecting' && (
              <div className="status-text">Connecting...</div>
            )}
            {connectionStatus === 'connected' && conversationActive && (
              <div className="status-text">Conversation Active</div>
            )}
            {connectionStatus === 'connected' && !conversationActive && (
              <div className="status-text">Connected</div>
            )}
            {connectionStatus === 'error' && (
              <div className="status-text error">Connection Error</div>
            )}
          </div>

          {/* Main calling interface */}
          <div className="calling-main">
            {/* Listening indicator */}
            <div className="listening-indicator">
              <motion.div
                className={`listening-circle ${isListening ? 'active' : ''}`}
                animate={isListening ? {
                  scale: [1, 1.2, 1],
                  opacity: [0.7, 1, 0.7]
                } : {}}
                transition={{
                  duration: 1.5,
                  repeat: isListening ? Infinity : 0,
                  ease: "easeInOut"
                }}
              >
                <div className="inner-circle">
                  {isListening ? (
                    <motion.div
                      className="listening-text"
                      animate={{ opacity: [0.5, 1, 0.5] }}
                      transition={{ duration: 1, repeat: Infinity }}
                    >
                      Listening...
                    </motion.div>
                  ) : isBotSpeaking ? (
                    <div className="bot-speaking-text">
                      Bot is speaking...
                    </div>
                  ) : (
                    <div className="waiting-text">
                      {isWelcomeSpoken ? 'Speak now...' : 'Connecting...'}
                    </div>
                  )}
                </div>
              </motion.div>
            </div>

            {/* End call button */}
            <motion.button
              className="end-call-btn"
              onClick={handleEndCall}
              whileHover={{ scale: 1.05 }}
              whileTap={{ scale: 0.95 }}
            >
              <Phone size={24} />
              End Call
            </motion.button>
          </div>

          {/* Disclaimer */}
          <div className="calling-disclaimer">
            <p>OrthoBot AI can sometimes make mistakes. Always consult with a doctor for medical advice.</p>
          </div>
        </motion.div>
      </motion.div>
    </AnimatePresence>
  );
};

export default VoiceCallingInterface;